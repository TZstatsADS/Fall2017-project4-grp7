{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Memory-based Algorithm\n",
    "\n",
    "#### step 1: Load Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from load_data1 import load_data1\n",
    "from load_data2 import load_data2\n",
    "\n",
    "# load ms data:\n",
    "ms_train = pd.read_csv('../data/MS_sample/data_train.csv',usecols=range(1,4))\n",
    "ms_test = pd.read_csv('../data/MS_sample/data_test.csv',usecols=range(1,4))\n",
    "\n",
    "\n",
    "ms_train_df = load_data1(ms_train) # train in pandas dataframe format \n",
    "ms_test_pd =  load_data1(ms_test) # test in pandas dataframe format\n",
    "\n",
    "ms_train_np=ms_train_df.as_matrix()  # train in numpy matrix format \n",
    "ms_test_np=ms_test_pd.as_matrix() # test in numpy matrix format\n",
    "\n",
    "np.save('../output/train1_matrix',ms_train_np)\n",
    "np.save('../output/test1_matrix',ms_test_np)\n",
    "\n",
    "ms_train_df.to_csv('../output/train1_df.csv',header=True,index=True)\n",
    "ms_test_pd.to_csv('../output/test1_df.csv',header=True,index=True)\n",
    "\n",
    "# load each_movie data:\n",
    "movie_train = pd.read_csv('../data/eachmovie_sample/data_train.csv',usecols=[\"Movie\",\"User\",\"Score\"])\n",
    "movie_test = pd.read_csv('../data/eachmovie_sample/data_test.csv',usecols=[\"Movie\",\"User\",\"Score\"])\n",
    "\n",
    "train2_df=load_data2(movie_train)\n",
    "test2_df=load_data2(movie_test)\n",
    "\n",
    "train2_df.to_csv('../output/train2_df.csv',header=True,index=True)\n",
    "test2_df.to_csv('../output/test2_df.csv', header=True, index=True)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### step2: Similarity Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pearson_correlation import pearsonSimi1\n",
    "from pearson_correlation import pearsonSimi2\n",
    "from vector_similarity import cosineSimi1\n",
    "from vector_similarity import cosineSimi2\n",
    "from simrank import simrank\n",
    "\n",
    "\n",
    "pearson_correlation1=pearsonSimi1(train1_df)\n",
    "pearson_correlation2=pearsonSimi2(train2_df)\n",
    "\n",
    "cosine_correlation1=cosineSimi1(train1_df)\n",
    "cosine_correlation2=cosineSimi2(train2_df)\n",
    "\n",
    "\n",
    "\n",
    "pearson_correlation1.to_pickle(\"../output/pearson_correlation1.pkl\")\n",
    "pearson_correlation2.to_pickle(\"../output/pearson_correlation2.pkl\")\n",
    "cosine_correlation1.to_pickle(\"../output/cosine_correlation1.pkl\")\n",
    "cosine_correlation2.to_pickle(\"../output/cosine_correlation2.pkl\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model-based Algorithm\n",
    "\n",
    "#### step 1: load data (MS data is assigned for this algorithm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from load_data1 import load_data1\n",
    "\n",
    "ms_train = pd.read_csv('../data/MS_sample/data_train.csv',usecols=range(1,4))\n",
    "ms_test = pd.read_csv('../data/MS_sample/data_test.csv',usecols=range(1,4))\n",
    "\n",
    "\n",
    "ms_train_df = load_data1(ms_train) # train in pandas dataframe \n",
    "ms_test_pd =  load_data1(ms_test) # test in pandas dataframe\n",
    "\n",
    "ms_train_np=ms_train_df.as_matrix()  # train in numpy matrix \n",
    "ms_test_np=ms_test_pd.as_matrix() # test in numpy matrix\n",
    "\n",
    "\n",
    "# save data\n",
    "\n",
    "#np.save('../output/train1_matrix',ms_train_np)\n",
    "#np.save('../output/test1_matrix',ms_test_np)\n",
    "\n",
    "#ms_train_df.to_csv('../output/train1_df.csv',header=True,index=True)\n",
    "#ms_test_pd.to_csv('../output/test1_df.csv',header=True,index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### step 2: train mixture model using EM algorithm\n",
    "#### Here we use 3 clusters for example. Later cross-validation is used for choosing the number of clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from cluster_model import train_cluster_model\n",
    "from cluster_model import select_stable_models\n",
    "import os\n",
    "\n",
    "X=np.load(\"../output/train1_matrix.npy\")   # train in numpy matrix \n",
    "train_df=pd.read_csv(\"../output/train1_df.csv\",index_col=0) # train in pandas dataframe\n",
    "test_df=pd.read_csv(\"../output/test1_df.csv\",index_col=0) # test in pandas dataframe\n",
    "\n",
    "\"\"\"\n",
    "X: user matrix \n",
    "   each row Xi=[vi1,vi2,...,vin]\n",
    "   Each row is a users and it records every user's votes\n",
    "\n",
    "k: number of clusters\n",
    "\"\"\"\n",
    "\n",
    "# here take k=3 for example:\n",
    "\n",
    "THETA,A,c=train_cluster_model(X,k) # train mixture model\n",
    "\n",
    "# save model\n",
    "filename='cluster_'+str(k)+'_model.npz'\n",
    "base_dir=\"../output\"\n",
    "np.savez(os.path.join(base_dir,filename),THETA=THETA,A=A,c=c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### step 3: prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from part2_prediction_matrix import mixture_model_prediction\n",
    "\n",
    "mixture_model=np.load(\"../output/cluster_3_model.npz\") # load model\n",
    "train_df=pd.read_csv(\"../output/train1_df.csv\",index_col=0)\n",
    "    \n",
    "THETA=mixture_model['THETA']\n",
    "A=mixture_model['A'] #assign matrix\n",
    "prediction_matrix=mixture_model_prediction(A,THETA) # get prediction matrix\n",
    "    \n",
    "# transform numpy matrix to pandas matrix\n",
    "\n",
    "prediction_df=pd.DataFrame(prediction_matrix)\n",
    "prediction_df.index=train_df.index\n",
    "prediction_df.columns=train_df.columns\n",
    "   \n",
    "prediction_df.to_csv(\"../output/train1_prediction_df.csv\",header=True,index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### step 4: evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from ranked_scoring import ranked_score\n",
    "\n",
    "cluster3_score=ranked_score(test_df,prediction_df)\n",
    "print (cluster3_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### step 5: choose the number of clusters\n",
    "As shown above, ranked score for k=3 is got. We used this method to get the cluster with highest ranked score.\n",
    "It should be known that select_stable_models is used here. This function will repeat train_cluster function 10 times and select the model with highest log likelihood. It is because sometimes the model is not the optimal model if it is just trained once. But after 10 times it should be a stable model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# K is a range of number of clusters.\n",
    "# get the ranked_score for cluster 3 - cluster 20\n",
    "    K=range(3,21)\n",
    "    cluster_scores=[]\n",
    "    for k in K:\n",
    "        THETA,A,c,log_likelihood=select_stable_models(X,k)\n",
    "        prediction_df=mixture_model_prediction(A,THETA)\n",
    "        # transform numpy matrix to pandas dataframe\n",
    "        prediction_df=pd.DataFrame(prediction_df)\n",
    "        prediction_df.index=train_df.index\n",
    "        prediction_df.columns=train_df.columns\n",
    "\n",
    "        cluster_score=ranked_score(test_df,prediction_df)\n",
    "        cluster_scores.append(cluster_score)\n",
    "print(cluster_scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output is :\n",
    "[81.988519767745032,\n",
    " 79.850197156108479,\n",
    " 78.15185123921205,\n",
    " 70.530292271372431,\n",
    " 75.295554154425162,\n",
    " 73.033652276173811,\n",
    " 68.861695574890973,\n",
    " 74.153784419504106,\n",
    " 77.004353981220802,\n",
    " 70.585141069716869,\n",
    " 70.879506091305586,\n",
    " 73.525475762373318,\n",
    " 72.013816579444793,\n",
    " 72.687744999995289,\n",
    " 75.569944504156027,\n",
    " 72.808830626227945,\n",
    " 68.287269638291136,\n",
    " 71.986778485624086]\n",
    " \n",
    " So we choose k=3 for our model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
